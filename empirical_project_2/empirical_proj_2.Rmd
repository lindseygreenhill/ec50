---
title: "empirical_proj_2"
author: "Lindsey Greenhill"
date: "4/9/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(haven)
library(rdrobust)
library(statar)
library(vtable)
library(ggthemes)
library(sandwich)
library(stargazer)
library(ggpubr)
library(lmtest)

data <- read_dta("third_grade.dta")
```

## Question 1

The fundamental problem of causal inference is that you cannot see the outcome
for a child who both was in a small class and not in a small class. In other
words, it is impossible to measure the dual outcomes when a child both is in a
small class and not in a small class, because the child can only either be in a
small class or not in a small class.

## Question 2

The following variables have missing values:

- towncode: 318 missing
- math: 58 missing
- verb: 466 missing
- ses_index: 318 missing
- boy: 1037 missing

```{r echo=FALSE}
summary(data)
```

## Questions 3 and 4

```{r echo=FALSE, results = "asis"}

# getting the means

math_mean <- mean(data$math, na.rm = T)
verb_mean <- mean(data$verb, na.rm = T)

# getting the sds

math_sd <- sd(data$math, na.rm = T)
verb_sd <- sd(data$verb, na.rm = T)

# standardizing

data$math_std <- (data$math - math_mean) / math_sd
data$verbal_std <- (data$verb - verb_mean) / verb_sd

# creating test score index

data <- data %>%
  mutate(test_score_index = .5 * (math_std + verbal_std)) %>%
  mutate(math_miss = if_else(is.na(math),
                             1,
                             0),
         verb_miss = if_else(is.na(verb),
                                1,
                                0)) %>%
  mutate(test_score_index = if_else(is.na(test_score_index),
                                    if_else(math_miss == 1, verbal_std, math_std),
                                    test_score_index))


# summary table

sumtable(data,
         vars = c("math", "verb", "test_score_index"),
         summ = c("mean(x)",
                  "sd(x)",
                  "min(x)",
                  "max(x)"),
         out = "latex")

```

## Question 5

All of the histograms appear to not by symmetrical and all of them have a long
left tail.

```{r echo=FALSE, warning = FALSE}

# math hist

hist_math <- data %>%
  ggplot(aes(x = math,
             y = ..density..)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of Math Scores") +
  theme_clean()


# verbal hist

hist_verb <- data %>%
  ggplot(aes(x = verb,
             y = ..density..)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of Verbal Scores") +
  theme_clean()

# index hist

hist_index <- data %>%
  ggplot(aes(x = test_score_index,
             y = ..density..)) +
  geom_histogram(binwidth = .25) +
  labs(title = "Distribution of Test Score Index") +
  theme_clean()

ggarrange(hist_math,
          hist_verb,
          hist_index)

```

## Question 6

```{r echo=FALSE, warning = FALSE}

# creating binned scatter plots

bin_index_ses <- data %>%
  ggplot(aes(x = ses_index, y = test_score_index)) +
  stat_binmean(n = 20, geom = "point") +
  labs(title = "Test Score Index vs. SES Index") +
  theme_classic()

bin_class_ses <- data %>%
  ggplot(aes(x = ses_index, y = class_size)) +
  stat_binmean(n = 20, geom = "point") +
  labs(title = "Class Size vs. SES Index") +
  theme_classic()
  
bin_index_class <- data %>%
  ggplot(aes(x = class_size, y = test_score_index)) +
  stat_binmean(n = 20, geom = "point") +
  labs(title = "Test Score Index vs. Class Size") +
  theme_classic()

ggarrange(bin_index_ses,
          bin_class_ses,
          bin_index_class)

```

## Question 7

As we can see from the binned scatter plots above, the socio economic
index variable is correlated with both class size and test score index.
As such, it is a counfounding variable and mean we cannot interpret 
the relationship between class size and test scores causally because
it is likely that a student's socioeconomic status influences both 
outcomes, meaning that we don't know how greatly class size affects
test scores versus ses affects test scores.

## Question 8

### Part a

I chose a quadratic model it seems to fit the data better than a linear model,
especiaally for the data to the left of the break

```{r echo=FALSE}

narrow <- data %>%
  filter(school_enrollment <= 80)

# I chose a quadratic because it seems to fit the data better, especially for
# the data to the left of the break

rdplot(narrow$class_size,
       narrow$school_enrollment,
       c = 41,
       p = 2,
       nbins = c(20,20),
       y.lim = c(0, 40),
       binselect = "es",
       title = "Class size vs. total school enrollment",
       x.label = "Total School Enrollment in 3rd Grade",
       y.label = "Class Size")
```

### Part b

I chose to use a linear model because it seems to fit the data better than a
quadrtatic model. When I chose a quadrataic model, it seemed like residuals on
the right side of the break were much more in the positive than the negative,
which would be bad. Looking at the graph, it doesn't seem like there is a wide
gap in schools with 40 kids and schools with 41 kids enrolled. 

```{r echo=FALSE}

# switching the varibale from above
rdplot(narrow$test_score_index,
       narrow$school_enrollment,
       c = 41,
       p = 1,
       nbins = c(20,20),
       y.lim = c(-.75, .5),
       binselect = "es",
       title = "Test Score Index vs. Total School Enrollment",
       x.label = "Total School Enrollment in 3rd Grade",
       y.label = "Test Score Index")
```

## Question 9

### Part a

```{r echo=FALSE}
# religious, boy (with test score index), born_isr

by_school_narrow <- data %>%
  group_by(schlcode) %>%
  mutate(avg_boy = mean(boy, na.rm = T),
         avg_religious = mean(religious, na.rm = T),
         avg_born_isr = mean(born_isr, na.rm = T)) %>%
  filter(school_enrollment <= 80)

# there doesn't appear to be a significant gap in % boys

rdplot(by_school_narrow$avg_boy,
       by_school_narrow$school_enrollment,
       c = 41,
       p = 1,
       nbins = c(20,20),
       y.lim = c(0, 1),
       binselect = "es",
       title = "% Boys vs. Total School Enrollment",
       x.label = "Total School Enrollment in 3rd Grade",
       y.label = "% Boys")

# there doesn't appear to be a significant gap in % borrn in isr

rdplot(by_school_narrow$avg_born_isr,
       by_school_narrow$school_enrollment,
       c = 41,
       p = 1,
       nbins = c(20,20),
       y.lim = c(.5, 1.2),
       binselect = "es",
       title = "% Born in Isr vs. Total School Enrollment",
       x.label = "Total School Enrollment in 3rd Grade",
       y.label = "% Born in Isr")

```

### Part b

The identification assumption for the regression discontinuity design is 
that schools on either side of the cutoff are similar in all ways and as such
the fact that they have school enrollment over or under the cutoff is as if
random. The graphs from part a above are consistent with this identification
assumption, as schools just at either side of the cutoff do not seem to have
different percentages of boys or kids born in Israel enrolled.

## Question 10

### Part a

Manipulation of school enrollment could possibly invalidate the identification assumption because it means that schools could
intentially stay right below the discontinuity cutoff, meaning
that the schools on either side of the cutoff would be 
different in this way. 

### Parts b, c, and d

```{r echo=FALSE, message=FALSE}

# aggregating data by school
schools <- data %>%
  group_by(schlcode) %>%
  summarise(enrollment = mean(school_enrollment),
            avg_class_size = mean(class_size, na.rm = T),
            avg_test_score_index = mean(test_score_index, na.rm = T))

schools %>%
  ggplot(aes(x = enrollment),
         y = ..density..) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of Total School Enrollment",
       subtitle = "Red lines aat 41, 81, and 121") +
  geom_vline(xintercept = 41, col = "red") +
  geom_vline(xintercept = 81, col = "red") +
  geom_vline(xintercept = 121, col = "red")+
  theme_classic()
```

Looking at the histogram above, it seems like there is a spike in enrollment
number right after the break at 41. However, there seems to be a drastic drop
off in enrollment right at the 81 threshold line. As such, it certainly seems
possible that there was manipulation in enrollment, but there are conflicting
behvaviors at the two cutoffs. There doesn't appear to be any spike at the 121
line.

## Question 11

```{r echo=FALSE, results="asis"}

# creating running variable, centered at 41

schools$dist_from_41 <- schools$enrollment - 41

# create indicator for being over threshold

schools$above41 <- 0

schools$above41[which(schools$enrollment >= 41)] <- 1 

schools$interaction41 <- schools$dist_from_41* schools$above41 

school_narrow <- schools %>%
  filter(enrollment <= 80)

# regressions

mod_classsize <- lm(avg_class_size ~ above41 + dist_from_41 + interaction41 , data = school_narrow) 

mod_testscore <- lm(avg_test_score_index ~ above41 + dist_from_41 + interaction41 , data = school_narrow) 

# displaying regressions

stargazer(mod_classsize, mod_testscore,
          type = "latex")



```
- For the test score model, the estimate of the discontinuity
at the 41 threshold = .026. 

- For the class size model, the estimate of the discontinuity
at the 41 threshold = -16.6

## Question 12

- Class size model: The 95% confidence interval for the above41 estimate = [-18.38, -14.8]. Because the CI does not include 0, we can
conclude that the results are statistically significant from 0 at the 95% confidence level

- Test score model: The 95% confidence interval for the above41 estimate = [-.14, .19]. Because the CI includes 0, we can
conclude that the results are not statistically significant from 0 at the 95% confidence level

```{r echo=FALSE}

# class size

cs_test <- coeftest(mod_classsize, vcov = vcovHC(mod_classsize, type="HC1")) 

lb_cs <- -16.6 - (1.96*.912)
ub_cs <- -16.6 + (1.96*.912)

# test score

ts_test <- coeftest(mod_testscore, vcov = vcovHC(mod_testscore, type="HC1")) 

lb_ts <- .026 - (1.96*.083)
ub_ts <- .026 + (1.96*.083)
```

## Question 13 

\newpage

```{r echo=FALSE, results = "asis", message=FALSE, warning=FALSE}

#First threshold is when wvar is less than or equal to 61 
schools$dist_from_cut <- ifelse(schools$enrollment <= 61,  
                                schools$enrollment - 41, 
                                NA) 
 
#Next threshold is when wvar is above 61 and less than or equal to 101 
schools$dist_from_cut <- ifelse(schools$enrollment > 61 & schools$enrollment <= 101, 
                                schools$enrollment - 81, 
                                schools$dist_from_cut) 
 
#Next threshold is when wvar is above 101 and less than or equal to 141 
schools$dist_from_cut <- ifelse(schools$enrollment > 101 & schools$enrollment <= 141, 
                                schools$enrollment - 121, 
                                schools$dist_from_cut) 
 
#Last threshold is when wvar is above 141 
schools$dist_from_cut <- ifelse(schools$enrollment > 141, 
                                schools$enrollment - 161, 
                                schools$dist_from_cut) 

# summary of variable

sumtable(schools,
         vars = c("dist_from_cut"),
         summ = c("mean(x)",
                  "sd(x)",
                  "min(x)",
                  "max(x)"),
         out = "latex")



```

\newpage

## Question 14

```{r warning=FALSE, message=FALSE, echo=FALSE}

# class size vs. dist from cut

cs_dc <- rdplot(schools$avg_class_size,
       schools$dist_from_cut,
       c = 0,
       p = 1,
       nbins = c(20,20),
       y.lim = c(0, 50),
       binselect = "es",
       title = "Class Size vs. Dist from Cut",
       x.label = "Distance from Cut",
       y.label = "Class Size")

# test score index vs dist from cut

ts_dc <- rdplot(schools$avg_test_score_index,
       schools$dist_from_cut,
       c = 0,
       p = 1,
       nbins = c(20,20),
       y.lim = c(-.5, .5),
       binselect = "es",
       title = "Test Score Index vs. Dist from Cut",
       x.label = "Distance from Cut",
       y.label = "Test Score Index")

```


## Question 15

- The estimated discontinuity for the class size model = -14.202.

- The estimated discontinuity for the test score model = -.008

```{r echo=FALSE, warning=FALSE, results = "asis"}

# creating regression terms

schools$above_cut <- 0

schools$above_cut[which(schools$dist_from_cut >= 0)] <- 1 

schools$interaction_cut <- schools$dist_from_cut* schools$above_cut 

# narrowing data set

schools_15 <- schools %>%
  filter(dist_from_cut <= 20,
         dist_from_cut >= -20)

# regression 

mod_class_size15 <- lm(avg_class_size ~ above_cut + dist_from_cut + interaction_cut, data = schools_15)

mod_test_score15 <- lm(avg_test_score_index ~ above_cut + dist_from_cut + interaction_cut, data = schools_15)

stargazer(mod_class_size15,
          mod_test_score15,
          type = "latex")

```


\newpage

## Question 16

The standard error is smaller in this model (both the class size and the test
score mdoel than the previous model (the one limited to the first cutoff point),
meaning that this model gives us more precise estimates than the model just
including the 41 student enrollment cutoff.

- The 95% CI for above_cut variable in the class size model is [-15.6, -12.79].
Because this interval does not contain 0, the can conclude the estimate is
statistically siignificant from 0 at the 95% confidence level.

- The 95% CI for above_cut variable in the test score model is [-.106, .09].
Because this interval contains 0, the can conclude the estimate is not
statistically siignificant from 0 at the 95% confidence level.


```{r echo=FALSE}

# class size

cs_test15 <- coeftest(mod_class_size15, vcov = vcovHC(mod_class_size15, type="HC1")) 

lb_cs15 <- -14.2 - (1.96*.715)
ub_cs15 <- -14.2 + (1.96*.715)

# test score

ts_test15 <- coeftest(mod_test_score15, vcov = vcovHC(mod_test_score15, type="HC1")) 

lb_ts15 <- -.008 - (1.96*.05)
ub_ts15 <- -.008 + (1.96*.05)

```






