---
title: "week_4_lab"
author: "Lindsey Greenhill"
date: "2/23/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(haven)
library(ggthemes)
library(stargazer)
library(gt)

star <- read_dta("star.dta")
```

## Question 1
  
  It is important to randomize the teachers in addition to the students because
  teachers could have significant impacts on the results of the study. For
  example, if we didn't randomize teachers and good tearchers happened to be
  more likely to teach small classes than bad teachers, then we would get a
  result that tells us small classes produce better results than large classes,
  but the driving force behind that finding would be teacher quality and not
  class size.

## Question 2

```{r echo=FALSE}
star %>%
  group_by(small) %>%
  summarise(avg_class = mean(class_size, na.rm = T)) %>%
  gt()

```


The average class sizes are shown in the table above. As expected, class sizes
are smaller in the classes assigned to be small than in the classes assigned
to be large. 

## Question 3

```{r echo=FALSE}

# I will go back and make this into a function if I have time

# math

# calculating control meaan and sd

control_mean_m <- star %>%
  filter(small == 0) %>%
  summarise(mean = mean(math, na.rm=T)) %>%
  as.double()
control_sd_m <- star %>%
  filter(small == 0) %>%
  summarise(sd = sd(math, na.rm=T)) %>%
  as.double()

# creating a new col

star <- star %>%
  mutate(standard_math = (math - control_mean_m)/control_sd_m)

# repeating steps above

# read

control_mean_r <- star %>%
  filter(small == 0) %>%
  summarise(mean = mean(read, na.rm=T)) %>%
  as.double()
control_sd_r <- star %>%
  filter(small == 0) %>%
  summarise(sd = sd(read, na.rm=T)) %>%
  as.double()
star <- star %>%
  mutate(standard_read = (read - control_mean_r)/control_sd_r)

# wordskill

control_mean_s <- star %>%
  filter(small == 0) %>%
  summarise(mean = mean(wordskill, na.rm=T)) %>%
  as.double()
control_sd_s <- star %>%
  filter(small == 0) %>%
  summarise(sd = sd(wordskill, na.rm=T)) %>%
  as.double()
star <- star %>%
  mutate(standard_wordskill = 
           (wordskill - control_mean_s)/control_sd_s)

# listen

control_mean_l <- star %>%
  filter(small == 0) %>%
  summarise(mean = mean(listen, na.rm=T)) %>%
  as.double()
control_sd_l <- star %>%
  filter(small == 0) %>%
  summarise(sd = sd(listen, na.rm=T)) %>%
  as.double()
star <- star %>%
  mutate(standard_listen = (listen - control_mean_l)/control_sd_l)

# calculating sat_index. for some reason mean function isn't working

star_new <- star %>%
  mutate(sat_index = (standard_math + standard_read + 
                        standard_wordskill + standard_listen)/4)

# plotting a histogram

star_new %>%
  ggplot(aes(x = sat_index, y = ..density..)) +
  geom_histogram(bins = 30) +
  facet_wrap(~small) +
  theme_clean() +
  labs(title = "Distribution of sat_index by class size")

```

The histograms look very similar to each other. The treatment group histogram
may be shifted slightly to the right, but it is difficult to tell. 

\newpage

## Question 4

```{r echo=FALSE, results = "asis"}

# creating new dataframe by class

by_teacher <- star_new %>%
  group_by(teacher_id, small, school_id, teacher_masters, teacher_white,
         teacher_black, teacher_experience) %>%
  summarise(avg_index = mean(sat_index, na.rm = T))

# creating regression for small

mod_1 <- lm(teacher_experience ~ small, data = by_teacher)


# creating regression for teacher_masters

mod_2 <- lm(teacher_masters ~ small, data = by_teacher)


# creating regression for teacher_white

mod_3 <- lm(teacher_white ~ small, data = by_teacher)


# teacher_black regression

mod_4 <- lm(teacher_black ~ small, data = by_teacher)


stargazer(mod_1, mod_2, mod_3, mod_4,
          type = "latex")
```


- teacher_experience: The standard error for the small coefficient = .6649. 
1.96 x .6649 = 1.303. The resulting 95% confidence interval 
of the coefficient = -.4107 +/- 1.303. Or [-1.7137, .8923].

- teacher_masters: The standard error for the small coefficient = .05426.
1.96 x .05426 = .1063. The resulting 95% confidence interval for the coefficient
= -.0408 +/- .1063. Or [-.1471, .06554]

- teacher_white: the small standard error = .04174. The small coefficient =
.04291. The 95% confidence interval = .04291 +/- 1.96*.04174 or [-.0389,.1247]

- teacher_black: the small standard error = .04143. The small coefficient = -.03786. 
The 95% CI = -.0376 +/- 1.96*.04143 or [-.119,.0433]

- The differences in teacher characteristics in small vs. large class sizes are
not statistically significant for any of the characteristics we looked at above.
This means that statistically the randomization was successful in balancing
teacher characteristics. From the practical standard, the values for
teacher_experience do not seem practically significant because they refer to a
difference of about 1 year which doesn't seem like a lot. The teacher masters
seems to bit more practically significant, as the lower bound of the confidence
interval implies about a 15% difference between the two groups of teachers. Both
the teacher_white and teacher_black results also seem a bit practically
significant because the greatest bounds of the confidence intervals suggest a
12.5%  and 11.9% difference in groups, respectively. However, overall these
differences do not seem overly troubliing to me and I think we still have 
comparable teacher groups. 

## Question 5


```{r echo=FALSE}

# part a

mod_5 <- lm(avg_index ~ small + factor(school_id),
            data = by_teacher)

# part b

# sd(by_teacher$avg_index)



# the coefficient for small = .16917 and the se = .02269

# part c

means <- by_teacher %>%
  group_by(small) %>%
  summarise(mean_index = mean(avg_index))

col_data <- tibble(group = c("control", "treatment"),
                   mean_index = c(.009, .171),
                   se = c(NA, .041))
col_data$ub <- col_data$mean_index + 1.96*col_data$se
col_data$lb <- col_data$mean_index - 1.96*col_data$se

col_data %>%
  ggplot(aes(x = group, y = mean_index)) +
  geom_col(fill = "azure3") +
  geom_errorbar(aes(ymin = lb, ymax = ub),
                width = .1) +
  theme_clean() +
  labs(title = "Average sat index scores for large (control) \nand small (treatment) classes")


```

- The coefficient estimate for small = .162. The SE = .041. The 95% CI = [.082,
.224]. This value is statistically significant. This means that on average,
small classes had average sat_index scores .162 higher than not small classes,
holding all else constant. The standard deviation for the average sat_index in
the data set = .5. Our estimate is within this one standard deviation, so it
does not seem very practically significant to me.




